# Generated by Copilot
"""
DeepSeek V3 Agent Integration for PolyMind

Triển khai agent sử dụng DeepSeek V3 model thông qua Together.xyz API.
"""

import os
import asyncio
import httpx
import json
from typing import Dict, List, Optional, Any, AsyncGenerator
from dataclasses import dataclass

from . import BaseAgent, AgentType, AgentResponse, MessageRole
from ..config import config


@dataclass
class DeepSeekConfig:
    """Cấu hình cho DeepSeek agent."""
    api_key: str
    base_url: str = "https://api.together.xyz/v1"
    model: str = "deepseek-ai/DeepSeek-V3"
    max_tokens: int = 2048
    temperature: float = 0.7
    timeout: int = 30


class DeepSeekAgent(BaseAgent):
    """
    DeepSeek V3 Agent sử dụng Together.xyz API.
    
    Agent này cung cấp khả năng:
    - Reasoning mạnh mẽ
    - Code generation và debugging
    - Phân tích và giải quyết vấn đề
    - Hỗ trợ tiếng Việt
    """
    
    def __init__(self, config: DeepSeekConfig):
        super().__init__(
            agent_type=AgentType.DEEPSEEK,
            name="DeepSeek V3",
            description="AI Agent with advanced reasoning capabilities powered by DeepSeek V3"
        )
        
        self.config = config
        self.client = httpx.AsyncClient(
            base_url=config.base_url,
            timeout=config.timeout,
            headers={
                "Authorization": f"Bearer {config.api_key}",
                "Content-Type": "application/json"
            }
        )
    
    async def chat(self, message: str, **kwargs) -> AgentResponse:
        """
        Gửi tin nhắn đến DeepSeek V3 và nhận response.
        
        Args:
            message: Tin nhắn từ user
            **kwargs: Tham số bổ sung (temperature, max_tokens, etc.)
            
        Returns:
            AgentResponse với phản hồi từ DeepSeek V3
        """
        try:
            # Thêm tin nhắn user vào conversation
            self.add_message(MessageRole.USER, message)
            
            # Chuẩn bị messages cho API
            messages = self._prepare_messages()
            
            # Gọi API
            response = await self._make_api_call(messages, **kwargs)
            
            # Parse response
            assistant_message = response["choices"][0]["message"]["content"]
            usage = response.get("usage", {})
            
            # Thêm response vào conversation
            self.add_message(MessageRole.ASSISTANT, assistant_message)
            
            return AgentResponse(
                content=assistant_message,
                agent_type=self.agent_type,
                model_name=self.config.model,
                usage=usage,
                metadata={"response_id": response.get("id")}
            )
            
        except Exception as e:
            error_msg = f"Lỗi khi gọi DeepSeek API: {str(e)}"
            return AgentResponse(
                content=error_msg,
                agent_type=self.agent_type,
                model_name=self.config.model,
                metadata={"error": True, "error_type": type(e).__name__}
            )
    
    async def stream_chat(self, message: str, **kwargs) -> AsyncGenerator[str, None]:
        """
        Stream response từ DeepSeek V3.
        
        Args:
            message: Tin nhắn từ user
            **kwargs: Tham số bổ sung
            
        Yields:
            Từng phần của response
        """
        try:
            # Thêm tin nhắn user vào conversation
            self.add_message(MessageRole.USER, message)
            
            # Chuẩn bị messages cho API
            messages = self._prepare_messages()
            
            # Stream API call
            full_response = ""
            async for chunk in self._stream_api_call(messages, **kwargs):
                if chunk:
                    full_response += chunk
                    yield chunk
            
            # Thêm full response vào conversation
            if full_response:
                self.add_message(MessageRole.ASSISTANT, full_response)
                
        except Exception as e:
            yield f"Lỗi khi stream từ DeepSeek API: {str(e)}"
    
    def _prepare_messages(self) -> List[Dict[str, str]]:
        """Chuẩn bị messages cho API call."""
        messages = [{"role": "system", "content": self._get_enhanced_system_prompt()}]
        
        # Thêm conversation context
        conversation_messages = self.get_conversation_context(max_messages=20)
        messages.extend(conversation_messages)
        
        return messages
    
    def _get_enhanced_system_prompt(self) -> str:
        """System prompt được tối ưu cho DeepSeek V3."""
        return """Bạn là DeepSeek V3, một AI assistant thông minh với khả năng reasoning mạnh mẽ.

Đặc điểm của bạn:
- Suy luận logic và phân tích sâu sắc
- Hỗ trợ lập trình và debugging xuất sắc  
- Giải thích rõ ràng, dễ hiểu
- Hỗ trợ tiếng Việt tự nhiên
- Cung cấp examples và code khi cần thiết

Hãy trả lời một cách chi tiết, logic và hữu ích. Sử dụng markdown formatting khi phù hợp."""
    
    async def _make_api_call(self, messages: List[Dict], **kwargs) -> Dict[str, Any]:
        """Thực hiện API call đến Together.xyz."""
        payload = {
            "model": self.config.model,
            "messages": messages,
            "max_tokens": kwargs.get("max_tokens", self.config.max_tokens),
            "temperature": kwargs.get("temperature", self.config.temperature),
            "stream": False
        }
        
        response = await self.client.post("/chat/completions", json=payload)
        response.raise_for_status()
        return response.json()
    
    async def _stream_api_call(self, messages: List[Dict], **kwargs) -> AsyncGenerator[str, None]:
        """Stream API call đến Together.xyz."""
        payload = {
            "model": self.config.model,
            "messages": messages,
            "max_tokens": kwargs.get("max_tokens", self.config.max_tokens),
            "temperature": kwargs.get("temperature", self.config.temperature),
            "stream": True
        }
        
        async with self.client.stream("POST", "/chat/completions", json=payload) as response:
            response.raise_for_status()
            
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    data = line[6:]  # Remove "data: " prefix
                    
                    if data == "[DONE]":
                        break
                    
                    try:
                        json_data = json.loads(data)
                        delta = json_data["choices"][0]["delta"]
                        
                        if "content" in delta:
                            yield delta["content"]
                            
                    except (json.JSONDecodeError, KeyError, IndexError):
                        continue
    
    async def analyze_code(self, code: str, language: str = "python") -> AgentResponse:
        """
        Phân tích code và đưa ra suggestions.
        
        Args:
            code: Source code cần phân tích
            language: Ngôn ngữ lập trình
            
        Returns:
            AgentResponse với phân tích code
        """
        prompt = f"""Hãy phân tích đoạn code {language} sau và đưa ra feedback:

```{language}
{code}
```

Vui lòng phân tích:
1. Code quality và best practices
2. Potential bugs hoặc issues
3. Performance optimization suggestions
4. Security considerations (nếu có)
5. Suggestions for improvement

Trả lời bằng tiếng Việt và sử dụng markdown formatting."""
        
        return await self.chat(prompt)
    
    async def explain_concept(self, concept: str, level: str = "intermediate") -> AgentResponse:
        """
        Giải thích concept một cách chi tiết.
        
        Args:
            concept: Khái niệm cần giải thích
            level: Mức độ (beginner, intermediate, advanced)
            
        Returns:
            AgentResponse với giải thích
        """
        prompt = f"""Hãy giải thích khái niệm "{concept}" ở mức độ {level}.

Vui lòng bao gồm:
1. Định nghĩa rõ ràng
2. Tại sao concept này quan trọng
3. Examples thực tế
4. Use cases phổ biến
5. Related concepts

Trả lời bằng tiếng Việt, dễ hiểu và có structure rõ ràng."""
        
        return await self.chat(prompt)
    
    async def solve_problem(self, problem: str, context: str = "") -> AgentResponse:
        """
        Giải quyết vấn đề với reasoning step-by-step.
        
        Args:
            problem: Vấn đề cần giải quyết
            context: Context bổ sung
            
        Returns:
            AgentResponse với solution
        """
        prompt = f"""Vấn đề: {problem}

{f"Context: {context}" if context else ""}

Hãy giải quyết vấn đề này với approach step-by-step:
1. Phân tích vấn đề
2. Identify key factors
3. Brainstorm solutions
4. Evaluate options
5. Recommend best solution
6. Implementation steps

Sử dụng reasoning logic và trả lời bằng tiếng Việt."""
        
        return await self.chat(prompt)
    
    async def close(self):
        """Đóng connection."""
        await self.client.aclose()
    
    @property
    def info(self) -> Dict[str, Any]:
        """Thông tin chi tiết về DeepSeek agent."""
        base_info = super().info
        base_info.update({
            "model": self.config.model,
            "provider": "Together.xyz",
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature,
            "capabilities": [
                "Advanced reasoning",
                "Code analysis",
                "Problem solving", 
                "Vietnamese support",
                "Streaming responses"
            ]
        })
        return base_info


def create_deepseek_agent(api_key: Optional[str] = None) -> DeepSeekAgent:
    """
    Factory function để tạo DeepSeek agent.
    
    Args:
        api_key: Together.xyz API key (nếu None sẽ lấy từ config)
        
    Returns:
        DeepSeekAgent instance
    """
    if api_key is None:
        api_key = config.TOGETHER_API_KEY
        
    if not api_key:
        raise ValueError("TOGETHER_API_KEY environment variable hoặc api_key parameter là required")
    
    deepseek_config = DeepSeekConfig(
        api_key=api_key,
        base_url=config.TOGETHER_BASE_URL,
        model=config.DEEPSEEK_MODEL,
        max_tokens=config.DEEPSEEK_MAX_TOKENS,
        temperature=config.DEEPSEEK_TEMPERATURE
    )
    return DeepSeekAgent(deepseek_config)
