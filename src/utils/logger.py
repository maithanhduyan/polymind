# Generated by Copilot
"""
High-Performance Async Logging System for PolyMind - Text Format

Provides non-blocking, async-aware logging with traditional text formatting:
- Async queue-based logging to prevent I/O blocking
- Traditional text format for better readability
- Rotating file handlers to manage disk space
- Configurable buffering for batch writes
- Context-aware logging for request tracing
"""

import asyncio
import logging
import sys
import time
import uuid
from asyncio import Queue
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional, Union, List
from logging.handlers import RotatingFileHandler


class AsyncLogHandler:
    """
    Async-aware log handler với queue-based processing.
    
    Tất cả log records được đưa vào queue và xử lý bởi background thread,
    không block main event loop.
    """
    
    def __init__(
        self,
        max_queue_size: int = 10000,
        batch_size: int = 100,
        flush_interval: float = 1.0,
        max_workers: int = 2
    ):
        self.log_queue: Queue = Queue(maxsize=max_queue_size)
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.handlers: List[logging.Handler] = []
        self.is_running = False
        self._background_task: Optional[asyncio.Task] = None
        
    def add_handler(self, handler: logging.Handler) -> None:
        """Thêm handler để xử lý log records."""
        self.handlers.append(handler)
        
    async def start(self) -> None:
        """Khởi động background processing."""
        if self.is_running:
            return
            
        self.is_running = True
        self._background_task = asyncio.create_task(self._process_logs())
        
    async def stop(self) -> None:
        """Dừng background processing và flush remaining logs."""
        self.is_running = False
        if self._background_task:
            await self._background_task
            
        # Flush remaining logs
        await self._flush_remaining()
        
    async def log_async(self, record: logging.LogRecord) -> None:
        """Async log method - không block."""
        try:
            self.log_queue.put_nowait(record)
        except asyncio.QueueFull:
            # Fallback: log to stderr nếu queue full
            print(f"Log queue full, dropping: {record.getMessage()}", file=sys.stderr)
            
    async def _process_logs(self) -> None:
        """Background task xử lý log queue."""
        batch = []
        last_flush = time.time()
        
        while self.is_running or not self.log_queue.empty():
            try:
                # Collect batch hoặc timeout
                while len(batch) < self.batch_size:
                    try:
                        record = await asyncio.wait_for(
                            self.log_queue.get(), timeout=0.1
                        )
                        batch.append(record)
                    except asyncio.TimeoutError:
                        break
                
                # Flush nếu có batch hoặc timeout
                current_time = time.time()
                if batch and (
                    len(batch) >= self.batch_size or 
                    current_time - last_flush >= self.flush_interval
                ):
                    await self._flush_batch(batch)
                    batch.clear()
                    last_flush = current_time
                    
            except Exception as e:
                print(f"Error in log processing: {e}", file=sys.stderr)
                
        # Final flush
        if batch:
            await self._flush_batch(batch)
            
    async def _flush_batch(self, batch: List[logging.LogRecord]) -> None:
        """Flush batch of log records to handlers."""
        if not batch or not self.handlers:
            return
            
        def write_logs():
            for record in batch:
                for handler in self.handlers:
                    try:
                        handler.emit(record)
                    except Exception as e:
                        print(f"Handler error: {e}", file=sys.stderr)
                        
        # Chạy I/O trong thread pool
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(self.executor, write_logs)
        
    async def _flush_remaining(self) -> None:
        """Flush all remaining logs."""
        remaining = []
        try:
            while True:
                record = self.log_queue.get_nowait()
                remaining.append(record)
        except asyncio.QueueEmpty:
            pass
            
        if remaining:
            await self._flush_batch(remaining)


class TextFormatter(logging.Formatter):
    """Formatter để tạo traditional text logs với context support."""
    
    def __init__(self, include_context: bool = True):
        # Format: 2025-06-20 09:15:30,123 [INFO] module.function:42 - Message
        super().__init__(
            fmt="%(asctime)s [%(levelname)s] %(name)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S"
        )
        self.include_context = include_context
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record thành text với context support."""
        # Base formatting
        formatted = super().format(record)
        
        if not self.include_context:
            return formatted
              # Thêm context information nếu có
        context_parts = []
        
        # Thêm request_id nếu có
        request_id = getattr(record, 'request_id', None)
        if request_id:
            context_parts.append(f"req_id={request_id}")
            
        # Thêm context nếu có
        context = getattr(record, 'context', None)
        if context and isinstance(context, dict):
            context_str = " ".join([f"{k}={v}" for k, v in context.items()])
            context_parts.append(context_str)
            
        # Thêm function info nếu có
        if hasattr(record, 'funcName') and record.funcName:
            context_parts.append(f"func={record.funcName}")
            
        if hasattr(record, 'lineno') and record.lineno:
            context_parts.append(f"line={record.lineno}")
        
        # Append context to message
        if context_parts:
            context_info = " | ".join(context_parts)
            formatted = f"{formatted} | {context_info}"
            
        # Thêm exception info nếu có
        if record.exc_info:
            formatted += "\n" + self.formatException(record.exc_info)
            
        return formatted


class AsyncLogger:
    """
    High-performance async logger với traditional text format.
    
    Features:
    - Non-blocking logging via async queue
    - Traditional text output for readability
    - Request/context tracking
    - Rotating file handlers
    - Performance optimized
    """
    
    def __init__(self, name: str, async_handler: AsyncLogHandler):
        self.name = name
        self.async_handler = async_handler
        self._context: Dict[str, Any] = {}
        self._request_id: Optional[str] = None
        
    def set_context(self, **kwargs) -> None:
        """Set logging context for this logger instance."""
        self._context.update(kwargs)
        
    def clear_context(self) -> None:
        """Clear logging context."""
        self._context.clear()
        
    def set_request_id(self, request_id: str) -> None:
        """Set request ID for tracing."""
        self._request_id = request_id
        
    def generate_request_id(self) -> str:
        """Generate và set new request ID."""
        request_id = str(uuid.uuid4())[:8]
        self.set_request_id(request_id)
        return request_id
        
    async def _log(self, level: int, message: str, **kwargs) -> None:
        """Internal async logging method."""
        record = logging.LogRecord(
            name=self.name,
            level=level,
            pathname="",
            lineno=0,
            msg=message,
            args=(),
            exc_info=None
        )
        
        # Thêm context
        if self._context:
            setattr(record, 'context', self._context.copy())
            
        # Thêm request_id
        if self._request_id:
            setattr(record, 'request_id', self._request_id)
            
        # Thêm extra kwargs
        for key, value in kwargs.items():
            setattr(record, key, value)
            
        await self.async_handler.log_async(record)
        
    async def debug(self, message: str, **kwargs) -> None:
        """Log debug message."""
        await self._log(logging.DEBUG, message, **kwargs)
        
    async def info(self, message: str, **kwargs) -> None:
        """Log info message."""
        await self._log(logging.INFO, message, **kwargs)
        
    async def warning(self, message: str, **kwargs) -> None:
        """Log warning message."""
        await self._log(logging.WARNING, message, **kwargs)
        
    async def error(self, message: str, **kwargs) -> None:
        """Log error message."""
        await self._log(logging.ERROR, message, **kwargs)
        
    async def critical(self, message: str, **kwargs) -> None:
        """Log critical message."""
        await self._log(logging.CRITICAL, message, **kwargs)


class AsyncLoggerConfig:
    """Async-aware logger configuration manager với text format."""
    
    _configured = False
    _async_handler: Optional[AsyncLogHandler] = None
    _loggers: Dict[str, AsyncLogger] = {}
    
    @classmethod
    async def configure_logging(
        cls,
        level: int = logging.INFO,
        log_to_file: bool = True,
        log_file_path: Optional[Path] = None,
        max_file_size: int = 10 * 1024 * 1024,  # 10MB
        backup_count: int = 5,
        include_context: bool = True,
        max_queue_size: int = 10000,
        batch_size: int = 100,
        flush_interval: float = 1.0
    ) -> None:
        """
        Configure async logging system với text format.
        
        Args:
            level: Logging level
            log_to_file: Enable file logging
            log_file_path: Path to log file
            max_file_size: Max size per log file
            backup_count: Number of backup files
            include_context: Include context in text format
            max_queue_size: Max async queue size
            batch_size: Batch size for processing
            flush_interval: Flush interval in seconds
        """
        if cls._configured:
            return
            
        # Create async handler
        cls._async_handler = AsyncLogHandler(
            max_queue_size=max_queue_size,
            batch_size=batch_size,
            flush_interval=flush_interval
        )
        
        # Formatter
        formatter = TextFormatter(include_context=include_context)
            
        # Console handler (stderr)
        console_handler = logging.StreamHandler(sys.stderr)
        console_handler.setLevel(level)
        console_handler.setFormatter(formatter)
        cls._async_handler.add_handler(console_handler)
        
        # File handler với rotation
        if log_to_file:
            if log_file_path is None:
                log_file_path = Path("logs/polymind.log")
                
            log_file_path.parent.mkdir(parents=True, exist_ok=True)
            
            file_handler = RotatingFileHandler(
                log_file_path,
                maxBytes=max_file_size,
                backupCount=backup_count,
                encoding="utf-8"
            )
            file_handler.setLevel(level)
            file_handler.setFormatter(formatter)
            cls._async_handler.add_handler(file_handler)
            
        # Start async processing
        await cls._async_handler.start()
        
        cls._configured = True
        
    @classmethod
    async def get_logger(cls, name: str) -> AsyncLogger:
        """Get async logger instance."""
        if not cls._configured:
            await cls.configure_logging()
            
        if name not in cls._loggers and cls._async_handler:
            cls._loggers[name] = AsyncLogger(name, cls._async_handler)
            
        return cls._loggers[name]
        
    @classmethod
    async def shutdown(cls) -> None:
        """Shutdown logging system."""
        if cls._async_handler:
            await cls._async_handler.stop()
            cls._configured = False


# Global async logger instance
_global_config = AsyncLoggerConfig()


async def get_logger(name: str) -> AsyncLogger:
    """
    Get async logger instance với text format.
    
    Args:
        name: Logger name (typically __name__)
        
    Returns:
        AsyncLogger instance
        
    Example:
        logger = await get_logger(__name__)
        await logger.info("Text log message")
    """
    return await _global_config.get_logger(name)


async def configure_logging(**kwargs) -> None:
    """Configure async logging system với text format."""
    await _global_config.configure_logging(**kwargs)


async def shutdown_logging() -> None:
    """Shutdown logging system gracefully."""
    await _global_config.shutdown()


# Context manager for request tracing
class LogContext:
    """Context manager cho request-scoped logging."""
    
    def __init__(self, logger: AsyncLogger, **context):
        self.logger = logger
        self.context = context
        self.old_context = {}
        
    async def __aenter__(self):
        self.old_context = self.logger._context.copy()
        self.logger.set_context(**self.context)
        return self.logger
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        self.logger._context = self.old_context


# Decorator for automatic request ID generation
def with_request_id(func):
    """Decorator tự động tạo request ID cho async functions."""
    async def wrapper(*args, **kwargs):
        logger = await get_logger(func.__module__)
        request_id = logger.generate_request_id()
        
        async with LogContext(logger, request_id=request_id):
            await logger.info(f"Starting {func.__name__}")
            try:
                result = await func(*args, **kwargs)
                await logger.info(f"Completed {func.__name__}")
                return result
            except Exception as e:
                await logger.error(f"Error in {func.__name__}: {e}")
                raise
                
    return wrapper


# Convenience functions for quick logging
async def log_info(message: str, logger_name: str = "__main__", **kwargs) -> None:
    """Quick info logging."""
    logger = await get_logger(logger_name)
    await logger.info(message, **kwargs)


async def log_error(message: str, logger_name: str = "__main__", **kwargs) -> None:
    """Quick error logging."""
    logger = await get_logger(logger_name)
    await logger.error(message, **kwargs)


async def log_debug(message: str, logger_name: str = "__main__", **kwargs) -> None:
    """Quick debug logging."""
    logger = await get_logger(logger_name)
    await logger.debug(message, **kwargs)
