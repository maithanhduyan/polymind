# C·∫•u tr√∫c D·ª± √°n nh∆∞ sau:

```
..\polymind
‚îú‚îÄ‚îÄ frontend
‚îÇ   ‚îú‚îÄ‚îÄ app.js
‚îÇ   ‚îú‚îÄ‚îÄ chat.html
‚îÇ   ‚îú‚îÄ‚îÄ chat.js
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îî‚îÄ‚îÄ styles.css
‚îú‚îÄ‚îÄ log_structure_report.py
‚îú‚îÄ‚îÄ logs
‚îÇ   ‚îú‚îÄ‚îÄ polymind.log
‚îÇ   ‚îî‚îÄ‚îÄ polymind_backup_20250620_081200.log
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ adapters
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
‚îÇ   ‚îú‚îÄ‚îÄ agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deepseek.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ manager.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboard.py
‚îÇ   ‚îú‚îÄ‚îÄ services
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py
‚îÇ   ‚îî‚îÄ‚îÄ utils
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ async_logger.py
‚îÇ       ‚îî‚îÄ‚îÄ logger.py
‚îú‚îÄ‚îÄ standardize_logging.py
‚îî‚îÄ‚îÄ uv.lock
```

# Danh s√°ch chi ti·∫øt c√°c file:

## File ..\polymind\log_structure_report.py:
```python
# Generated by Copilot
"""
PolyMind Log Structure Analysis and Standardization Report

PROBLEM IDENTIFIED:
The log file (logs/polymind.log) had inconsistent structure with mixed content:

1. TEST LOGS:
   - Format: 2025-06-20 02:54:55 [DEBUG] test_basic - Debug message
   - Components: test_basic, test_vietnamese, worker_1, worker_2, etc.
   - Source: Testing scripts and benchmark files

2. APPLICATION LOGS:
   - Format: 2025-06-20 02:56:52 [INFO] polymind_main - üìù Logger initialized
   - Components: polymind_main
   - Source: FastAPI application main.py

3. ENCODING ISSUES:
   - Some logs appeared with corrupted encoding despite UTF-8 configuration
   - Mixed content made log analysis difficult

STANDARDIZATION SOLUTION:
"""

import asyncio
from pathlib import Path
from datetime import datetime

class LogStructureStandardizer:
    """
    Standardizes PolyMind logging structure for consistent format.
    """
    
    UNIFIED_FORMAT = "YYYY-MM-DD HH:MM:SS [LEVEL] component - message"
    
    STANDARD_COMPONENTS = {
        "polymind_main": "Main application lifecycle",
        "polymind_websocket": "WebSocket connections and messages", 
        "polymind_agent": "AI agent operations",
        "polymind_api": "REST API endpoints",
        "polymind_config": "Configuration and environment",
        "polymind_error": "Error handling and exceptions"
    }
    
    @classmethod
    def get_recommendations(cls) -> dict:
        """Get recommendations for unified logging structure."""
        return {
            "format": cls.UNIFIED_FORMAT,
            "components": cls.STANDARD_COMPONENTS,
            "guidelines": [
                "Use emojis for visual clarity: üöÄ startup, üîå websocket, ‚ùå errors",
                "Vietnamese text fully supported with UTF-8 encoding",
                "Separate test logs from application logs", 
                "Use component-based logger names (not random test names)",
                "Maintain consistent message structure across modules",
                "Clean log file before production deployment"
            ],
            "examples": [
                "2025-06-20 15:30:45 [INFO] polymind_main - üöÄ PolyMind application starting...",
                "2025-06-20 15:30:46 [INFO] polymind_agent - ü§ñ DeepSeek agent initialized",
                "2025-06-20 15:30:47 [INFO] polymind_websocket - üîå WebSocket server ready on port 8000",
                "2025-06-20 15:30:48 [INFO] polymind_main - üáªüá≥ Ch√†o m·ª´ng ƒë·∫øn v·ªõi PolyMind!",
                "2025-06-20 15:30:49 [ERROR] polymind_error - ‚ùå Database connection failed"
            ]
        }
    
    @classmethod  
    def generate_clean_log_header(cls) -> str:
        """Generate clean header for log file."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return f"""# PolyMind Application Log - Unified Structure
# Generated: {timestamp}
# Format: {cls.UNIFIED_FORMAT}
#
# Standard Components:
{chr(10).join(f"# - {comp}: {desc}" for comp, desc in cls.STANDARD_COMPONENTS.items())}
#
# Guidelines:
# - Use emojis for visual clarity and quick scanning
# - Vietnamese text fully supported
# - Component-based logger names only
# - Consistent message structure
#
"""

def main():
    """Generate standardization report."""
    standardizer = LogStructureStandardizer()
    recommendations = standardizer.get_recommendations()
    
    print("üéØ PolyMind Log Structure Standardization Report")
    print("=" * 60)
    
    print(f"\nüìã UNIFIED FORMAT:")
    print(f"   {recommendations['format']}")
    
    print(f"\nüèóÔ∏è STANDARD COMPONENTS:")
    for comp, desc in recommendations['components'].items():
        print(f"   ‚Ä¢ {comp}: {desc}")
    
    print(f"\n‚úÖ GUIDELINES:")
    for guideline in recommendations['guidelines']:
        print(f"   ‚Ä¢ {guideline}")
    
    print(f"\nüìù EXAMPLES:")
    for example in recommendations['examples']:
        print(f"   {example}")
    
    # Generate clean log file
    log_file = Path("logs/polymind.log")
    if log_file.exists():
        # Backup existing log
        backup_file = Path(f"logs/polymind_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
        log_file.rename(backup_file)
        print(f"\nüì¶ Existing log backed up to: {backup_file}")
    
    # Create clean log file
    log_file.parent.mkdir(exist_ok=True)
    with open(log_file, 'w', encoding='utf-8') as f:
        f.write(standardizer.generate_clean_log_header())
    
    print(f"‚ú® Clean log file created: {log_file}")
    print(f"\nüéØ NEXT STEPS:")
    print("   1. Use only standard component names in logger calls")
    print("   2. Update main.py to use polymind_* component names")
    print("   3. Separate test logs from application logs")
    print("   4. Remove benchmark and test files from workspace")
    print("   5. Restart application to begin unified logging")

if __name__ == "__main__":
    main()

```

## File ..\polymind\standardize_logging.py:
```python
#!/usr/bin/env python3
"""
Log Structure Standardization Script

This script ensures consistent logging format across the PolyMind application.
Standardizes all logs to follow: YYYY-MM-DD HH:MM:SS [LEVEL] component - message

Key improvements:
1. Consistent logger names (no random test names)
2. Structured message format
3. Component-based logging (main, websocket, agent, etc.)
4. Vietnamese text support maintained
5. Emojis used consistently for visual clarity
"""

import asyncio
import logging
from datetime import datetime
from pathlib import Path
from src.utils.logger import get_logger

async def demonstrate_unified_logging():
    """Demonstrate the unified logging structure for PolyMind."""
    
    # Initialize loggers for different components
    main_logger = await get_logger("polymind_main")
    websocket_logger = await get_logger("polymind_websocket") 
    agent_logger = await get_logger("polymind_agent")
    api_logger = await get_logger("polymind_api")
    
    print("üîß Demonstrating unified logging structure...")
    print("üìÅ Log file: logs/polymind.log")
    print("üìã Format: YYYY-MM-DD HH:MM:SS [LEVEL] component - message\n")
      # Application startup logs
    await main_logger.info("üöÄ PolyMind application starting...")
    await main_logger.info("‚öôÔ∏è Configuration loaded successfully")
    await main_logger.info("‚úÖ Environment variables validated")
    
    # Agent logs  
    await agent_logger.info("ü§ñ DeepSeek agent initializing...")
    await agent_logger.info("‚úÖ DeepSeek agent registered successfully")
    await agent_logger.info("üß† Agent ready for conversations")
    
    # WebSocket logs
    await websocket_logger.info("üîå WebSocket server started on port 8000")
    await websocket_logger.info("üîó Client connected from 127.0.0.1")
    await websocket_logger.info("üí¨ Message received: Hello PolyMind!")
    await websocket_logger.info("üì§ Response sent to client")
    await websocket_logger.info("‚ùå Client disconnected")
    
    # API logs
    await api_logger.info("üåê REST API endpoints registered")
    await api_logger.info("üì° GET /health - Health check requested")
    await api_logger.info("üìä POST /chat - New chat session created")
    
    # Vietnamese content logs
    await main_logger.info("üáªüá≥ Ch√†o m·ª´ng ƒë·∫øn v·ªõi PolyMind!")
    await main_logger.info("üìù X·ª≠ l√Ω th√†nh c√¥ng tin nh·∫Øn ti·∫øng Vi·ªát")
    await main_logger.warning("‚ö†Ô∏è C·∫£nh b√°o: T·ª∑ l·ªá s·ª≠ d·ª•ng CPU cao")
    
    # Error handling logs
    try:
        raise ValueError("Simulated error for demonstration")
    except Exception as e:
        await main_logger.error(f"‚ùå Application error: {str(e)}")
        await main_logger.error("üîß Error handling activated")
    
    # Performance and monitoring logs
    await main_logger.info("üìä Processing 1,000 messages/second")
    await main_logger.info("üíæ Memory usage: 250MB")
    await main_logger.info("‚è±Ô∏è Average response time: 120ms")
    
    # Shutdown logs
    await websocket_logger.info("üîå WebSocket connections closed")
    await agent_logger.info("ü§ñ Agent cleanup completed")
    await main_logger.info("üõë PolyMind application shutdown complete")
    
    print("‚úÖ Unified logging demonstration completed!")
    print("üìÑ Check logs/polymind.log for structured output")

async def validate_log_structure():
    """Validate that logs follow the unified structure."""
    
    log_file = Path("logs/polymind.log")
    if not log_file.exists():
        print("‚ùå Log file not found!")
        return False
    
    print("\nüîç Validating log structure...")
    
    valid_components = {
        'polymind_main', 'polymind_websocket', 
        'polymind_agent', 'polymind_api'
    }
    
    issues_found = []
    
    with open(log_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    for i, line in enumerate(lines, 1):
        line = line.strip()
        if line.startswith('#') or not line:
            continue
            
        # Check format: YYYY-MM-DD HH:MM:SS [LEVEL] component - message
        parts = line.split(' - ', 1)
        if len(parts) != 2:
            issues_found.append(f"Line {i}: Missing ' - ' separator")
            continue
            
        timestamp_level_component = parts[0]
        message = parts[1]
        
        # Extract component from the line
        try:
            component_part = timestamp_level_component.split('] ')[1]
            if component_part not in valid_components:
                issues_found.append(f"Line {i}: Invalid component '{component_part}'")
        except IndexError:
            issues_found.append(f"Line {i}: Invalid format")
    
    if issues_found:
        print(f"‚ö†Ô∏è Found {len(issues_found)} issues:")
        for issue in issues_found[:5]:  # Show first 5 issues
            print(f"  ‚Ä¢ {issue}")
        if len(issues_found) > 5:
            print(f"  ‚Ä¢ ... and {len(issues_found) - 5} more")
        return False
    else:
        print("‚úÖ All logs follow unified structure!")
        return True

if __name__ == "__main__":
    print("üéØ PolyMind Log Structure Standardization")
    print("=" * 50)
    
    # Run the demonstration
    asyncio.run(demonstrate_unified_logging())
    
    # Validate the structure
    asyncio.run(validate_log_structure())
    
    print("\nüìã Logging Standards Summary:")
    print("‚Ä¢ Format: YYYY-MM-DD HH:MM:SS [LEVEL] component - message")
    print("‚Ä¢ Components: polymind_main, polymind_websocket, polymind_agent, polymind_api")
    print("‚Ä¢ Emojis: Used for visual clarity and quick scanning")
    print("‚Ä¢ Vietnamese: Full UTF-8 support maintained")
    print("‚Ä¢ Structure: Consistent across all application modules")

```

## File ..\polymind\src\config.py:
```python
# Generated by Copilot
"""
Configuration management for PolyMind project.
"""

import os
from typing import Optional


class Config:
    """Application configuration."""
    
    # Together.xyz API configuration
    TOGETHER_API_KEY: Optional[str] = os.getenv("TOGETHER_API_KEY")
    TOGETHER_BASE_URL: str = "https://api.together.xyz/v1"
    
    # DeepSeek model configuration
    DEEPSEEK_MODEL: str = "deepseek-ai/DeepSeek-V3"
    DEEPSEEK_MAX_TOKENS: int = 4000
    DEEPSEEK_TEMPERATURE: float = 0.7
    
    # Application settings
    DEBUG: bool = os.getenv("DEBUG", "false").lower() == "true"
    HOST: str = os.getenv("HOST", "127.0.0.1")
    PORT: int = int(os.getenv("PORT", "8000"))
    
    @classmethod
    def check_required_env(cls) -> bool:
        """Ki·ªÉm tra c√°c environment variables b·∫Øt bu·ªôc."""
        if not cls.TOGETHER_API_KEY:
            print("‚ùå TOGETHER_API_KEY environment variable is not set")
            print("üí° Please set your Together.xyz API key:")
            print("   export TOGETHER_API_KEY=your_api_key_here")
            return False
        return True


# Global config instance
config = Config()
```

## File ..\polymind\src\main.py:
```python
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pathlib import Path
import json
import asyncio
from datetime import datetime
from src.services.health import router as health_router
from src.agents.manager import agent_manager
from src.agents import AgentType, AgentResponse
from src.config import config
from src.utils.logger import get_logger

app = FastAPI(title="PolyMind App", description="Fast modern AI service framework")

# Initialize logger
logger = None

async def get_app_logger():
    """Get or initialize global logger for the application."""
    global logger
    if logger is None:
        logger = await get_logger("polymind_main")
        await logger.info("üìù Logger initialized for PolyMind main application")
    return logger

@app.on_event("startup")
async def startup_event():
    """Setup agents khi kh·ªüi ƒë·ªông app."""
    # Initialize logger first
    app_logger = await get_app_logger()
    
    await app_logger.info("üöÄ Starting PolyMind application...")
    
    # Ki·ªÉm tra environment variables
    if not config.check_required_env():
        await app_logger.warning("‚ö†Ô∏è  Some environment variables are missing. Some features may not work.")
        print("‚ö†Ô∏è  Some environment variables are missing. Some features may not work.")
    else:
        await app_logger.info("‚úÖ All required environment variables found")
    
    await agent_manager.setup_default_agents()
    await app_logger.info("‚úÖ Agent setup completed")
    print("‚úÖ Agent setup completed")

# WebSocket connection manager
class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        # Log connection
        if logger:
            await logger.info(f"üîå New WebSocket connection established. Total connections: {len(self.active_connections)}")

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)
        # Log disconnection (using sync logging for simplicity in sync method)
        if logger:
            import asyncio
            try:
                loop = asyncio.get_event_loop()
                loop.create_task(logger.info(f"üîå WebSocket connection closed. Remaining connections: {len(self.active_connections)}"))
            except:
                pass  # Failsafe if no event loop

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)

manager = ConnectionManager()

# Mount static files
app.mount("/static", StaticFiles(directory="frontend"), name="static")

# Include API routers
app.include_router(health_router)


# Serve frontend at root
@app.get("/")
async def serve_frontend():
    """Serve the main frontend page."""
    return FileResponse("frontend/index.html")


@app.get("/chat")
async def serve_chat():
    """Serve the main chat page."""
    return FileResponse("frontend/chat.html")


@app.get("/api")
async def api_root():
    """API root endpoint."""
    return {"status": "ok", "message": "PolyMind API is running"}


@app.get("/api/chat/agents")
async def get_chat_agents():
    """Get available chat agents."""
    agents = []
    for agent_id, agent_instance in agent_manager.agents.items():
        agent_info = agent_instance.info
        agents.append({
            "id": agent_id,
            "name": agent_info["name"],
            "description": agent_info["description"],
            "type": agent_info["type"],
            "conversation_length": agent_info.get("conversation_length", 0)
        })
    
    return {"agents": agents}


@app.get("/api/chat/agents/health")
async def get_agents_health():
    """Ki·ªÉm tra health c·ªßa t·∫•t c·∫£ agents."""
    return await agent_manager.health_check()


# WebSocket endpoint for chat
@app.websocket("/ws/chat")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    app_logger = await get_app_logger()
    
    try:
        while True:
            data = await websocket.receive_text()
            message_data = json.loads(data)
            
            # L·∫•y th√¥ng tin t·ª´ message
            user_message = message_data.get('content', '')
            agent_id = message_data.get('agent', 'deepseek')  # Default to deepseek
            is_streaming = message_data.get('streaming', False)
            
            # Log incoming message
            await app_logger.info(f"üí¨ Received message for agent '{agent_id}' (streaming: {is_streaming}): {user_message[:100]}{'...' if len(user_message) > 100 else ''}")
            
            try:
                if is_streaming:
                    # Streaming response
                    await manager.send_personal_message(json.dumps({
                        "type": "ai_typing",
                        "agent": agent_id
                    }), websocket)
                    
                    agent = agent_manager.get_agent(agent_id)
                    if agent:
                        response_content = ""
                        stream = await agent.stream_chat(user_message)
                        async for chunk in stream:
                            response_content += chunk
                            await manager.send_personal_message(json.dumps({
                                "type": "ai_chunk",
                                "content": chunk,
                                "agent": agent_id
                            }), websocket)
                          # G·ª≠i final response
                        await manager.send_personal_message(json.dumps({
                            "type": "ai_response",
                            "content": response_content,
                            "timestamp": datetime.now().isoformat(),
                            "agent": agent_id                        
                        }), websocket)
                        
                        # Log successful streaming response
                        await app_logger.info(f"‚úÖ Streaming response completed for agent '{agent_id}' - {len(response_content)} characters")
                    else:
                        await app_logger.error(f"‚ùå Agent '{agent_id}' kh√¥ng kh·∫£ d·ª•ng")
                        await manager.send_personal_message(json.dumps({
                            "type": "error",
                            "content": f"Agent '{agent_id}' kh√¥ng kh·∫£ d·ª•ng",
                            "timestamp": datetime.now().isoformat()
                        }), websocket)
                else:
                    # Regular response
                    response = await agent_manager.chat(user_message, agent_id)
                    
                    await manager.send_personal_message(json.dumps({
                        "type": "ai_response",
                        "content": response.content,
                        "timestamp": datetime.now().isoformat(),
                        "agent": agent_id,
                        "model": response.model_name
                    }), websocket)
                      # Log successful regular response
                    await app_logger.info(f"‚úÖ Regular response completed for agent '{agent_id}' using model '{response.model_name}' - {len(response.content)} characters")
                    
            except Exception as e:
                # Log error details
                await app_logger.error(f"‚ùå Error processing message for agent '{agent_id}': {str(e)}")
                # G·ª≠i error response
                await manager.send_personal_message(json.dumps({
                    "type": "error",
                    "content": f"L·ªói x·ª≠ l√Ω: {str(e)}",
                    "timestamp": datetime.now().isoformat()
                }), websocket)
            
    except WebSocketDisconnect:
        await app_logger.info("üîå WebSocket client disconnected")
        manager.disconnect(websocket)
    except Exception as e:
        await app_logger.error(f"‚ùå WebSocket error: {str(e)}")
        manager.disconnect(websocket)


def main() -> None:
    """Entry point ƒë·ªÉ ch·∫°y development server."""
    import uvicorn

    uvicorn.run("src.main:app", host="127.0.0.1", port=8000, reload=True)


if __name__ == "__main__":
    main()

```

## File ..\polymind\src\__init__.py:
```python
# Generated by Copilot
"""
PolyMind
Fast, modern AI service framework for vector database operations.
"""

__version__ = "0.1.0"
__author__ = "Mai Th√†nh Duy An"
__email__ = "tiachop0102@gmail.com"

# Import c√°c module ch√≠nh ƒë·ªÉ d·ªÖ d√†ng import t·ª´ package
from .main import app
# from .config import settings

# Public API - nh·ªØng g√¨ c√≥ th·ªÉ import t·ª´ b√™n ngo√†i
__all__ = [
    "app",
    "__version__",
]
```

## File ..\polymind\src\agents\deepseek.py:
```python
# Generated by Copilot
"""
DeepSeek V3 Agent Integration for PolyMind

Tri·ªÉn khai agent s·ª≠ d·ª•ng DeepSeek V3 model th√¥ng qua Together.xyz API.
"""

import os
import asyncio
import httpx
import json
from typing import Dict, List, Optional, Any, AsyncGenerator
from dataclasses import dataclass

from . import BaseAgent, AgentType, AgentResponse, MessageRole
from ..config import config


@dataclass
class DeepSeekConfig:
    """C·∫•u h√¨nh cho DeepSeek agent."""
    api_key: str
    base_url: str = "https://api.together.xyz/v1"
    model: str = "deepseek-ai/DeepSeek-V3"
    max_tokens: int = 2048
    temperature: float = 0.7
    timeout: int = 30


class DeepSeekAgent(BaseAgent):
    """
    DeepSeek V3 Agent s·ª≠ d·ª•ng Together.xyz API.
    
    Agent n√†y cung c·∫•p kh·∫£ nƒÉng:
    - Reasoning m·∫°nh m·∫Ω
    - Code generation v√† debugging
    - Ph√¢n t√≠ch v√† gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ
    - H·ªó tr·ª£ ti·∫øng Vi·ªát
    """
    
    def __init__(self, config: DeepSeekConfig):
        super().__init__(
            agent_type=AgentType.DEEPSEEK,
            name="DeepSeek V3",
            description="AI Agent with advanced reasoning capabilities powered by DeepSeek V3"
        )
        
        self.config = config
        self.client = httpx.AsyncClient(
            base_url=config.base_url,
            timeout=config.timeout,
            headers={
                "Authorization": f"Bearer {config.api_key}",
                "Content-Type": "application/json"
            }
        )
    
    async def chat(self, message: str, **kwargs) -> AgentResponse:
        """
        G·ª≠i tin nh·∫Øn ƒë·∫øn DeepSeek V3 v√† nh·∫≠n response.
        
        Args:
            message: Tin nh·∫Øn t·ª´ user
            **kwargs: Tham s·ªë b·ªï sung (temperature, max_tokens, etc.)
            
        Returns:
            AgentResponse v·ªõi ph·∫£n h·ªìi t·ª´ DeepSeek V3
        """
        try:
            # Th√™m tin nh·∫Øn user v√†o conversation
            self.add_message(MessageRole.USER, message)
            
            # Chu·∫©n b·ªã messages cho API
            messages = self._prepare_messages()
            
            # G·ªçi API
            response = await self._make_api_call(messages, **kwargs)
            
            # Parse response
            assistant_message = response["choices"][0]["message"]["content"]
            usage = response.get("usage", {})
            
            # Th√™m response v√†o conversation
            self.add_message(MessageRole.ASSISTANT, assistant_message)
            
            return AgentResponse(
                content=assistant_message,
                agent_type=self.agent_type,
                model_name=self.config.model,
                usage=usage,
                metadata={"response_id": response.get("id")}
            )
            
        except Exception as e:
            error_msg = f"L·ªói khi g·ªçi DeepSeek API: {str(e)}"
            return AgentResponse(
                content=error_msg,
                agent_type=self.agent_type,
                model_name=self.config.model,
                metadata={"error": True, "error_type": type(e).__name__}
            )
    
    async def stream_chat(self, message: str, **kwargs) -> AsyncGenerator[str, None]:
        """
        Stream response t·ª´ DeepSeek V3.
        
        Args:
            message: Tin nh·∫Øn t·ª´ user
            **kwargs: Tham s·ªë b·ªï sung
            
        Yields:
            T·ª´ng ph·∫ßn c·ªßa response
        """
        try:
            # Th√™m tin nh·∫Øn user v√†o conversation
            self.add_message(MessageRole.USER, message)
            
            # Chu·∫©n b·ªã messages cho API
            messages = self._prepare_messages()
            
            # Stream API call
            full_response = ""
            async for chunk in self._stream_api_call(messages, **kwargs):
                if chunk:
                    full_response += chunk
                    yield chunk
            
            # Th√™m full response v√†o conversation
            if full_response:
                self.add_message(MessageRole.ASSISTANT, full_response)
                
        except Exception as e:
            yield f"L·ªói khi stream t·ª´ DeepSeek API: {str(e)}"
    
    def _prepare_messages(self) -> List[Dict[str, str]]:
        """Chu·∫©n b·ªã messages cho API call."""
        messages = [{"role": "system", "content": self._get_enhanced_system_prompt()}]
        
        # Th√™m conversation context
        conversation_messages = self.get_conversation_context(max_messages=20)
        messages.extend(conversation_messages)
        
        return messages
    
    def _get_enhanced_system_prompt(self) -> str:
        """System prompt ƒë∆∞·ª£c t·ªëi ∆∞u cho DeepSeek V3."""
        return """B·∫°n l√† DeepSeek V3, m·ªôt AI assistant th√¥ng minh v·ªõi kh·∫£ nƒÉng reasoning m·∫°nh m·∫Ω.

ƒê·∫∑c ƒëi·ªÉm c·ªßa b·∫°n:
- Suy lu·∫≠n logic v√† ph√¢n t√≠ch s√¢u s·∫Øc
- H·ªó tr·ª£ l·∫≠p tr√¨nh v√† debugging xu·∫•t s·∫Øc  
- Gi·∫£i th√≠ch r√µ r√†ng, d·ªÖ hi·ªÉu
- H·ªó tr·ª£ ti·∫øng Vi·ªát t·ª± nhi√™n
- Cung c·∫•p examples v√† code khi c·∫ßn thi·∫øt

H√£y tr·∫£ l·ªùi m·ªôt c√°ch chi ti·∫øt, logic v√† h·ªØu √≠ch. S·ª≠ d·ª•ng markdown formatting khi ph√π h·ª£p."""
    
    async def _make_api_call(self, messages: List[Dict], **kwargs) -> Dict[str, Any]:
        """Th·ª±c hi·ªán API call ƒë·∫øn Together.xyz."""
        payload = {
            "model": self.config.model,
            "messages": messages,
            "max_tokens": kwargs.get("max_tokens", self.config.max_tokens),
            "temperature": kwargs.get("temperature", self.config.temperature),
            "stream": False
        }
        
        response = await self.client.post("/chat/completions", json=payload)
        response.raise_for_status()
        return response.json()
    
    async def _stream_api_call(self, messages: List[Dict], **kwargs) -> AsyncGenerator[str, None]:
        """Stream API call ƒë·∫øn Together.xyz."""
        payload = {
            "model": self.config.model,
            "messages": messages,
            "max_tokens": kwargs.get("max_tokens", self.config.max_tokens),
            "temperature": kwargs.get("temperature", self.config.temperature),
            "stream": True
        }
        
        async with self.client.stream("POST", "/chat/completions", json=payload) as response:
            response.raise_for_status()
            
            async for line in response.aiter_lines():
                if line.startswith("data: "):
                    data = line[6:]  # Remove "data: " prefix
                    
                    if data == "[DONE]":
                        break
                    
                    try:
                        json_data = json.loads(data)
                        delta = json_data["choices"][0]["delta"]
                        
                        if "content" in delta:
                            yield delta["content"]
                            
                    except (json.JSONDecodeError, KeyError, IndexError):
                        continue
    
    async def analyze_code(self, code: str, language: str = "python") -> AgentResponse:
        """
        Ph√¢n t√≠ch code v√† ƒë∆∞a ra suggestions.
        
        Args:
            code: Source code c·∫ßn ph√¢n t√≠ch
            language: Ng√¥n ng·ªØ l·∫≠p tr√¨nh
            
        Returns:
            AgentResponse v·ªõi ph√¢n t√≠ch code
        """
        prompt = f"""H√£y ph√¢n t√≠ch ƒëo·∫°n code {language} sau v√† ƒë∆∞a ra feedback:

```{language}
{code}
```

Vui l√≤ng ph√¢n t√≠ch:
1. Code quality v√† best practices
2. Potential bugs ho·∫∑c issues
3. Performance optimization suggestions
4. Security considerations (n·∫øu c√≥)
5. Suggestions for improvement

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v√† s·ª≠ d·ª•ng markdown formatting."""
        
        return await self.chat(prompt)
    
    async def explain_concept(self, concept: str, level: str = "intermediate") -> AgentResponse:
        """
        Gi·∫£i th√≠ch concept m·ªôt c√°ch chi ti·∫øt.
        
        Args:
            concept: Kh√°i ni·ªám c·∫ßn gi·∫£i th√≠ch
            level: M·ª©c ƒë·ªô (beginner, intermediate, advanced)
            
        Returns:
            AgentResponse v·ªõi gi·∫£i th√≠ch
        """
        prompt = f"""H√£y gi·∫£i th√≠ch kh√°i ni·ªám "{concept}" ·ªü m·ª©c ƒë·ªô {level}.

Vui l√≤ng bao g·ªìm:
1. ƒê·ªãnh nghƒ©a r√µ r√†ng
2. T·∫°i sao concept n√†y quan tr·ªçng
3. Examples th·ª±c t·∫ø
4. Use cases ph·ªï bi·∫øn
5. Related concepts

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, d·ªÖ hi·ªÉu v√† c√≥ structure r√µ r√†ng."""
        
        return await self.chat(prompt)
    
    async def solve_problem(self, problem: str, context: str = "") -> AgentResponse:
        """
        Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ v·ªõi reasoning step-by-step.
        
        Args:
            problem: V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt
            context: Context b·ªï sung
            
        Returns:
            AgentResponse v·ªõi solution
        """
        prompt = f"""V·∫•n ƒë·ªÅ: {problem}

{f"Context: {context}" if context else ""}

H√£y gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y v·ªõi approach step-by-step:
1. Ph√¢n t√≠ch v·∫•n ƒë·ªÅ
2. Identify key factors
3. Brainstorm solutions
4. Evaluate options
5. Recommend best solution
6. Implementation steps

S·ª≠ d·ª•ng reasoning logic v√† tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."""
        
        return await self.chat(prompt)
    
    async def close(self):
        """ƒê√≥ng connection."""
        await self.client.aclose()
    
    @property
    def info(self) -> Dict[str, Any]:
        """Th√¥ng tin chi ti·∫øt v·ªÅ DeepSeek agent."""
        base_info = super().info
        base_info.update({
            "model": self.config.model,
            "provider": "Together.xyz",
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature,
            "capabilities": [
                "Advanced reasoning",
                "Code analysis",
                "Problem solving", 
                "Vietnamese support",
                "Streaming responses"
            ]
        })
        return base_info


def create_deepseek_agent(api_key: Optional[str] = None) -> DeepSeekAgent:
    """
    Factory function ƒë·ªÉ t·∫°o DeepSeek agent.
    
    Args:
        api_key: Together.xyz API key (n·∫øu None s·∫Ω l·∫•y t·ª´ config)
        
    Returns:
        DeepSeekAgent instance
    """
    if api_key is None:
        api_key = config.TOGETHER_API_KEY
        
    if not api_key:
        raise ValueError("TOGETHER_API_KEY environment variable ho·∫∑c api_key parameter l√† required")
    
    deepseek_config = DeepSeekConfig(
        api_key=api_key,
        base_url=config.TOGETHER_BASE_URL,
        model=config.DEEPSEEK_MODEL,
        max_tokens=config.DEEPSEEK_MAX_TOKENS,
        temperature=config.DEEPSEEK_TEMPERATURE
    )
    return DeepSeekAgent(deepseek_config)

```

## File ..\polymind\src\agents\manager.py:
```python
# Generated by Copilot
"""
Agent Manager - Qu·∫£n l√Ω t·∫•t c·∫£ agents trong PolyMind system

Centralized management cho t·∫•t c·∫£ AI agents.
"""

import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

from . import BaseAgent, AgentType, AgentResponse
from .deepseek import DeepSeekAgent, create_deepseek_agent


@dataclass
class AgentInfo:
    """Th√¥ng tin v·ªÅ m·ªôt agent."""
    name: str
    type: AgentType
    description: str
    is_available: bool
    capabilities: List[str]
    model_info: Optional[Dict[str, Any]] = None


class AgentManager:
    """
    Manager ƒë·ªÉ qu·∫£n l√Ω v√† route requests ƒë·∫øn c√°c agents.
    
    Ch·ª©c nƒÉng:
    - Registry c√°c agents
    - Route messages ƒë·∫øn appropriate agent
    - Load balancing v√† fallback
    - Agent health monitoring
    """
    
    def __init__(self):
        self.agents: Dict[str, BaseAgent] = {}
        self._default_agent: Optional[str] = None
    
    def register_agent(self, agent_id: str, agent: BaseAgent, is_default: bool = False):
        """
        ƒêƒÉng k√Ω agent v√†o manager.
        
        Args:
            agent_id: Unique ID cho agent
            agent: BaseAgent instance
            is_default: C√≥ ph·∫£i default agent kh√¥ng
        """
        self.agents[agent_id] = agent
        
        if is_default or self._default_agent is None:
            self._default_agent = agent_id
    
    def get_agent(self, agent_id: Optional[str] = None) -> Optional[BaseAgent]:
        """
        L·∫•y agent theo ID.
        
        Args:
            agent_id: ID c·ªßa agent (None = default agent)
            
        Returns:
            BaseAgent instance ho·∫∑c None        """
        if agent_id is None:
            agent_id = self._default_agent
            
        if agent_id is None:
            return None
            
        return self.agents.get(agent_id)
    
    def list_agents(self) -> List[AgentInfo]:
        """Li·ªát k√™ t·∫•t c·∫£ agents c√≥ s·∫µn."""
        agent_infos = []
        
        for agent_id, agent in self.agents.items():
            info = agent.info
            agent_info = AgentInfo(
                name=info["name"],
                type=AgentType(info["type"]),
                description=info["description"],
                is_available=True,  # TODO: Implement health check
                capabilities=info.get("capabilities", []),
                model_info={
                    "model": info.get("model"),
                    "provider": info.get("provider")
                }
            )
            agent_infos.append(agent_info)
        
        return agent_infos
    
    async def chat(self, message: str, agent_id: Optional[str] = None, **kwargs) -> AgentResponse:
        """
        G·ª≠i message ƒë·∫øn agent.
        
        Args:
            message: Tin nh·∫Øn t·ª´ user
            agent_id: ID c·ªßa agent (None = default)
            **kwargs: Tham s·ªë b·ªï sung
            
        Returns:
            AgentResponse
        """
        agent = self.get_agent(agent_id)
        
        if agent is None:
            # Fallback response
            return AgentResponse(
                content="Xin l·ªói, agent kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng th·ª≠ l·∫°i sau.",
                agent_type=AgentType.GENERAL,
                model_name="fallback",
                metadata={"error": True, "reason": "agent_unavailable"}
            )
        
        return await agent.chat(message, **kwargs)
    
    async def setup_default_agents(self):
        """Thi·∫øt l·∫≠p c√°c agents m·∫∑c ƒë·ªãnh."""
        try:
            # DeepSeek agent (primary)
            deepseek_agent = create_deepseek_agent()
            self.register_agent("deepseek", deepseek_agent, is_default=True)
            
            print("‚úÖ DeepSeek agent registered successfully")
            
        except Exception as e:
            print(f"‚ùå Failed to setup DeepSeek agent: {e}")
            print("üí° H√£y ƒë·∫£m b·∫£o TOGETHER_API_KEY environment variable ƒë∆∞·ª£c set")
    
    async def health_check(self) -> Dict[str, Any]:
        """Ki·ªÉm tra health c·ªßa t·∫•t c·∫£ agents."""
        health_status = {
            "total_agents": len(self.agents),
            "healthy_agents": 0,
            "agents": {}
        }
        
        for agent_id, agent in self.agents.items():
            try:
                # Simple health check b·∫±ng c√°ch g·ªçi info
                agent_info = agent.info
                health_status["agents"][agent_id] = {
                    "status": "healthy",
                    "info": agent_info
                }
                health_status["healthy_agents"] += 1
                
            except Exception as e:                health_status["agents"][agent_id] = {
                    "status": "unhealthy",
                    "error": str(e)
                }
        
        return health_status
    
    async def close_all(self):
        """ƒê√≥ng t·∫•t c·∫£ agents."""
        for agent in self.agents.values():
            if hasattr(agent, 'close') and callable(getattr(agent, 'close', None)):
                try:
                    close_method = getattr(agent, 'close')
                    await close_method()
                except Exception as e:
                    print(f"Error closing agent: {e}")
    
    def get_agent_by_type(self, agent_type: AgentType) -> Optional[BaseAgent]:
        """L·∫•y agent theo type."""
        for agent in self.agents.values():
            if agent.agent_type == agent_type:
                return agent
        return None
    
    def get_capabilities(self) -> Dict[str, List[str]]:
        """L·∫•y capabilities c·ªßa t·∫•t c·∫£ agents."""
        capabilities = {}
        
        for agent_id, agent in self.agents.items():
            info = agent.info
            capabilities[agent_id] = info.get("capabilities", [])
        
        return capabilities


# Global agent manager instance
agent_manager = AgentManager()

```

## File ..\polymind\src\agents\__init__.py:
```python
# Generated by Copilot
"""
PolyMind Agent System - Base Agent Interface

ƒê·ªãnh nghƒ©a interface c∆° b·∫£n cho t·∫•t c·∫£ agents trong h·ªá th·ªëng.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any, AsyncGenerator
from dataclasses import dataclass
from enum import Enum
import asyncio
import time


class AgentType(Enum):
    """Lo·∫°i agent trong h·ªá th·ªëng."""
    GENERAL = "general"
    CODING = "coding" 
    ANALYSIS = "analysis"
    CREATIVE = "creative"
    DEEPSEEK = "deepseek"


class MessageRole(Enum):
    """Vai tr√≤ trong conversation."""
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"


@dataclass
class AgentMessage:
    """Tin nh·∫Øn trong conversation."""
    role: MessageRole
    content: str
    timestamp: float
    metadata: Optional[Dict[str, Any]] = None


@dataclass 
class AgentResponse:
    """Response t·ª´ agent."""
    content: str
    agent_type: AgentType
    model_name: str
    usage: Optional[Dict[str, Any]] = None
    metadata: Optional[Dict[str, Any]] = None
    timestamp: Optional[float] = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()


class BaseAgent(ABC):
    """Base class cho t·∫•t c·∫£ agents."""
    
    def __init__(self, agent_type: AgentType, name: str, description: str):
        self.agent_type = agent_type
        self.name = name
        self.description = description
        self.conversation_history: List[AgentMessage] = []
    
    @abstractmethod
    async def chat(self, message: str, **kwargs) -> AgentResponse:
        """
        G·ª≠i tin nh·∫Øn ƒë·∫øn agent v√† nh·∫≠n response.
        
        Args:
            message: Tin nh·∫Øn t·ª´ user
            **kwargs: C√°c tham s·ªë b·ªï sung
            
        Returns:
            AgentResponse v·ªõi n·ªôi dung ph·∫£n h·ªìi
        """
        pass
    
    @abstractmethod
    async def stream_chat(self, message: str, **kwargs) -> AsyncGenerator[str, None]:
        """
        Stream response t·ª´ agent.
        
        Args:
            message: Tin nh·∫Øn t·ª´ user
            **kwargs: C√°c tham s·ªë b·ªï sung
            
        Yields:
            T·ª´ng ph·∫ßn c·ªßa response
        """
        pass
    
    def add_message(self, role: MessageRole, content: str, metadata: Optional[Dict] = None):
        """Th√™m tin nh·∫Øn v√†o l·ªãch s·ª≠ conversation."""
        message = AgentMessage(
            role=role,
            content=content,
            timestamp=time.time(),
            metadata=metadata
        )
        self.conversation_history.append(message)
    
    def clear_conversation(self):
        """X√≥a l·ªãch s·ª≠ conversation."""
        self.conversation_history.clear()
    
    def get_conversation_context(self, max_messages: int = 10) -> List[Dict[str, str]]:
        """
        L·∫•y context conversation cho API calls.
        
        Args:
            max_messages: S·ªë tin nh·∫Øn t·ªëi ƒëa ƒë·ªÉ l·∫•y
            
        Returns:
            List c√°c tin nh·∫Øn theo format API
        """
        recent_messages = self.conversation_history[-max_messages:]
        return [
            {"role": msg.role.value, "content": msg.content}
            for msg in recent_messages
        ]
    
    def get_system_prompt(self) -> str:
        """L·∫•y system prompt cho agent."""
        return f"You are {self.name}, {self.description}"
    
    @property
    def info(self) -> Dict[str, Any]:
        """Th√¥ng tin v·ªÅ agent."""
        return {
            "name": self.name,
            "type": self.agent_type.value,
            "description": self.description,
            "conversation_length": len(self.conversation_history)
        }

```

## File ..\polymind\src\routes\chat.py:
```python

```

## File ..\polymind\src\routes\dashboard.py:
```python

```

## File ..\polymind\src\services\health.py:
```python
# src/services/health.py
from fastapi import APIRouter

router = APIRouter(prefix="/health", tags=["health"])

@router.get("/")
async def health_check():
    return {
        "status": "healthy", 
        "timestamp": "2025-06-20T...",
        "version": "1.0.0"
    }

@router.get("/detailed")
async def detailed_health():
    return {
        "status": "healthy",
        "database": "connected",
        "memory_usage": "45%",
        "uptime": "2h 30m"
    }
```

## File ..\polymind\src\utils\async_logger.py:
```python
# Generated by Copilot
"""
High-Performance Async Logging System for PolyMind

Provides non-blocking, async-aware logging with performance optimization:
- Async queue-based logging to prevent I/O blocking
- Structured JSON logging for better traceability
- Rotating file handlers to manage disk space
- Configurable buffering for batch writes
- Context-aware logging for request tracing
"""

import asyncio
import json
import logging
import sys
import time
import uuid
from asyncio import Queue
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional, Union, List
from logging.handlers import RotatingFileHandler


class AsyncLogHandler:
    """
    Async-aware log handler v·ªõi queue-based processing.
    
    T·∫•t c·∫£ log records ƒë∆∞·ª£c ƒë∆∞a v√†o queue v√† x·ª≠ l√Ω b·ªüi background thread,
    kh√¥ng block main event loop.
    """
    
    def __init__(
        self,
        max_queue_size: int = 10000,
        batch_size: int = 100,
        flush_interval: float = 1.0,
        max_workers: int = 2
    ):
        self.log_queue: Queue = Queue(maxsize=max_queue_size)
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.handlers: List[logging.Handler] = []
        self.is_running = False
        self._background_task: Optional[asyncio.Task] = None
        
    def add_handler(self, handler: logging.Handler) -> None:
        """Th√™m handler ƒë·ªÉ x·ª≠ l√Ω log records."""
        self.handlers.append(handler)
        
    async def start(self) -> None:
        """Kh·ªüi ƒë·ªông background processing."""
        if self.is_running:
            return
            
        self.is_running = True
        self._background_task = asyncio.create_task(self._process_logs())
        
    async def stop(self) -> None:
        """D·ª´ng background processing v√† flush remaining logs."""
        self.is_running = False
        if self._background_task:
            await self._background_task
            
        # Flush remaining logs
        await self._flush_remaining()
        
    async def log_async(self, record: logging.LogRecord) -> None:
        """Async log method - kh√¥ng block."""
        try:
            self.log_queue.put_nowait(record)
        except asyncio.QueueFull:
            # Fallback: log to stderr n·∫øu queue full
            print(f"Log queue full, dropping: {record.getMessage()}", file=sys.stderr)
            
    async def _process_logs(self) -> None:
        """Background task x·ª≠ l√Ω log queue."""
        batch = []
        last_flush = time.time()
        
        while self.is_running or not self.log_queue.empty():
            try:
                # Collect batch ho·∫∑c timeout
                while len(batch) < self.batch_size:
                    try:
                        record = await asyncio.wait_for(
                            self.log_queue.get(), timeout=0.1
                        )
                        batch.append(record)
                    except asyncio.TimeoutError:
                        break
                
                # Flush n·∫øu c√≥ batch ho·∫∑c timeout
                current_time = time.time()
                if batch and (
                    len(batch) >= self.batch_size or 
                    current_time - last_flush >= self.flush_interval
                ):
                    await self._flush_batch(batch)
                    batch.clear()
                    last_flush = current_time
                    
            except Exception as e:
                print(f"Error in log processing: {e}", file=sys.stderr)
                
        # Final flush
        if batch:
            await self._flush_batch(batch)
            
    async def _flush_batch(self, batch: List[logging.LogRecord]) -> None:
        """Flush batch of log records to handlers."""
        if not batch or not self.handlers:
            return
            
        def write_logs():
            for record in batch:
                for handler in self.handlers:
                    try:
                        handler.emit(record)
                    except Exception as e:
                        print(f"Handler error: {e}", file=sys.stderr)
                        
        # Ch·∫°y I/O trong thread pool
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(self.executor, write_logs)
        
    async def _flush_remaining(self) -> None:
        """Flush all remaining logs."""
        remaining = []
        try:
            while True:
                record = self.log_queue.get_nowait()
                remaining.append(record)
        except asyncio.QueueEmpty:
            pass
            
        if remaining:
            await self._flush_batch(remaining)


class StructuredFormatter(logging.Formatter):
    """Formatter ƒë·ªÉ t·∫°o structured JSON logs."""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record th√†nh JSON structure."""
        log_data = {
            "timestamp": datetime.fromtimestamp(record.created).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Th√™m context n·∫øu c√≥
        if hasattr(record, 'context'):
            log_data['context'] = getattr(record, 'context')
            
        # Th√™m request_id n·∫øu c√≥
        if hasattr(record, 'request_id'):
            log_data['request_id'] = getattr(record, 'request_id')
            
        # Th√™m exception info n·∫øu c√≥
        if record.exc_info:
            log_data['exception'] = self.formatException(record.exc_info)
            
        return json.dumps(log_data, ensure_ascii=False)


class AsyncLogger:
    """
    High-performance async logger v·ªõi context support.
    
    Features:
    - Non-blocking logging via async queue
    - Structured JSON output
    - Request/context tracking
    - Rotating file handlers
    - Performance optimized
    """
    
    def __init__(self, name: str, async_handler: AsyncLogHandler):
        self.name = name
        self.async_handler = async_handler
        self._context: Dict[str, Any] = {}
        self._request_id: Optional[str] = None
        
    def set_context(self, **kwargs) -> None:
        """Set logging context for this logger instance."""
        self._context.update(kwargs)
        
    def clear_context(self) -> None:
        """Clear logging context."""
        self._context.clear()
        
    def set_request_id(self, request_id: str) -> None:
        """Set request ID for tracing."""
        self._request_id = request_id
        
    def generate_request_id(self) -> str:
        """Generate v√† set new request ID."""
        request_id = str(uuid.uuid4())[:8]
        self.set_request_id(request_id)
        return request_id
        
    async def _log(self, level: int, message: str, **kwargs) -> None:
        """Internal async logging method."""
        record = logging.LogRecord(
            name=self.name,
            level=level,
            pathname="",
            lineno=0,
            msg=message,
            args=(),
            exc_info=None
        )
        
        # Th√™m context
        if self._context:
            setattr(record, 'context', self._context.copy())
            
        # Th√™m request_id
        if self._request_id:
            setattr(record, 'request_id', self._request_id)
            
        # Th√™m extra kwargs
        for key, value in kwargs.items():
            setattr(record, key, value)
            
        await self.async_handler.log_async(record)
        
    async def debug(self, message: str, **kwargs) -> None:
        """Log debug message."""
        await self._log(logging.DEBUG, message, **kwargs)
        
    async def info(self, message: str, **kwargs) -> None:
        """Log info message."""
        await self._log(logging.INFO, message, **kwargs)
        
    async def warning(self, message: str, **kwargs) -> None:
        """Log warning message."""
        await self._log(logging.WARNING, message, **kwargs)
        
    async def error(self, message: str, **kwargs) -> None:
        """Log error message."""
        await self._log(logging.ERROR, message, **kwargs)
        
    async def critical(self, message: str, **kwargs) -> None:
        """Log critical message."""
        await self._log(logging.CRITICAL, message, **kwargs)


class AsyncLoggerConfig:
    """Async-aware logger configuration manager."""
    
    _configured = False
    _async_handler: Optional[AsyncLogHandler] = None
    _loggers: Dict[str, AsyncLogger] = {}
    
    @classmethod
    async def configure_logging(
        cls,
        level: int = logging.INFO,
        log_to_file: bool = True,
        log_file_path: Optional[Path] = None,
        max_file_size: int = 10 * 1024 * 1024,  # 10MB
        backup_count: int = 5,
        structured: bool = True,
        max_queue_size: int = 10000,
        batch_size: int = 100,
        flush_interval: float = 1.0
    ) -> None:
        """
        Configure async logging system.
        
        Args:
            level: Logging level
            log_to_file: Enable file logging
            log_file_path: Path to log file
            max_file_size: Max size per log file
            backup_count: Number of backup files
            structured: Use JSON structured logging
            max_queue_size: Max async queue size
            batch_size: Batch size for processing
            flush_interval: Flush interval in seconds
        """
        if cls._configured:
            return
            
        # Create async handler
        cls._async_handler = AsyncLogHandler(
            max_queue_size=max_queue_size,
            batch_size=batch_size,
            flush_interval=flush_interval
        )
        
        # Formatter
        if structured:
            formatter = StructuredFormatter()
        else:
            formatter = logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
            
        # Console handler (stderr)
        console_handler = logging.StreamHandler(sys.stderr)
        console_handler.setLevel(level)
        console_handler.setFormatter(formatter)
        cls._async_handler.add_handler(console_handler)
        
        # File handler v·ªõi rotation
        if log_to_file:
            if log_file_path is None:
                log_file_path = Path("logs/polymind.log")
                
            log_file_path.parent.mkdir(parents=True, exist_ok=True)
            
            file_handler = RotatingFileHandler(
                log_file_path,
                maxBytes=max_file_size,
                backupCount=backup_count,
                encoding="utf-8"
            )
            file_handler.setLevel(level)
            file_handler.setFormatter(formatter)
            cls._async_handler.add_handler(file_handler)
            
        # Start async processing
        await cls._async_handler.start()
        
        cls._configured = True
        
    @classmethod
    async def get_logger(cls, name: str) -> AsyncLogger:
        """Get async logger instance."""
        if not cls._configured:
            await cls.configure_logging()
            
        if name not in cls._loggers and cls._async_handler:
            cls._loggers[name] = AsyncLogger(name, cls._async_handler)
            
        return cls._loggers[name]
        
    @classmethod
    async def shutdown(cls) -> None:
        """Shutdown logging system."""
        if cls._async_handler:
            await cls._async_handler.stop()
            cls._configured = False


# Global async logger instance
_global_config = AsyncLoggerConfig()


async def get_async_logger(name: str) -> AsyncLogger:
    """
    Get async logger instance.
    
    Args:
        name: Logger name (typically __name__)
        
    Returns:
        AsyncLogger instance
        
    Example:
        logger = await get_async_logger(__name__)
        await logger.info("Async log message")
    """
    return await _global_config.get_logger(name)


async def configure_async_logging(**kwargs) -> None:
    """Configure async logging system."""
    await _global_config.configure_logging(**kwargs)


async def shutdown_logging() -> None:
    """Shutdown logging system gracefully."""
    await _global_config.shutdown()


# Context manager for request tracing
class LogContext:
    """Context manager cho request-scoped logging."""
    
    def __init__(self, logger: AsyncLogger, **context):
        self.logger = logger
        self.context = context
        self.old_context = {}
        
    async def __aenter__(self):
        self.old_context = self.logger._context.copy()
        self.logger.set_context(**self.context)
        return self.logger
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        self.logger._context = self.old_context


# Decorator for automatic request ID generation
def with_request_id(func):
    """Decorator t·ª± ƒë·ªông t·∫°o request ID cho async functions."""
    async def wrapper(*args, **kwargs):
        logger = await get_async_logger(func.__module__)
        request_id = logger.generate_request_id()
        
        async with LogContext(logger, request_id=request_id):
            await logger.info(f"Starting {func.__name__}", function=func.__name__)
            try:
                result = await func(*args, **kwargs)
                await logger.info(f"Completed {func.__name__}", function=func.__name__)
                return result
            except Exception as e:
                await logger.error(
                    f"Error in {func.__name__}: {e}", 
                    function=func.__name__, 
                    error=str(e)
                )
                raise
                
    return wrapper

```

## File ..\polymind\src\utils\logger.py:
```python
# Generated by Copilot
"""
High-Performance Async Logging System for PolyMind - Text Format

Provides non-blocking, async-aware logging with traditional text formatting:
- Async queue-based logging to prevent I/O blocking
- Traditional text format for better readability
- Rotating file handlers to manage disk space
- Configurable buffering for batch writes
- Context-aware logging for request tracing
"""

import asyncio
import logging
import sys
import time
import uuid
from asyncio import Queue
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional, Union, List
from logging.handlers import RotatingFileHandler


class AsyncLogHandler:
    """
    Async-aware log handler v·ªõi queue-based processing.
    
    T·∫•t c·∫£ log records ƒë∆∞·ª£c ƒë∆∞a v√†o queue v√† x·ª≠ l√Ω b·ªüi background thread,
    kh√¥ng block main event loop.
    """
    
    def __init__(
        self,
        max_queue_size: int = 10000,
        batch_size: int = 100,
        flush_interval: float = 1.0,
        max_workers: int = 2
    ):
        self.log_queue: Queue = Queue(maxsize=max_queue_size)
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.handlers: List[logging.Handler] = []
        self.is_running = False
        self._background_task: Optional[asyncio.Task] = None
        
    def add_handler(self, handler: logging.Handler) -> None:
        """Th√™m handler ƒë·ªÉ x·ª≠ l√Ω log records."""
        self.handlers.append(handler)
        
    async def start(self) -> None:
        """Kh·ªüi ƒë·ªông background processing."""
        if self.is_running:
            return
            
        self.is_running = True
        self._background_task = asyncio.create_task(self._process_logs())
        
    async def stop(self) -> None:
        """D·ª´ng background processing v√† flush remaining logs."""
        self.is_running = False
        if self._background_task:
            await self._background_task
            
        # Flush remaining logs
        await self._flush_remaining()
        
    async def log_async(self, record: logging.LogRecord) -> None:
        """Async log method - kh√¥ng block."""
        try:
            self.log_queue.put_nowait(record)
        except asyncio.QueueFull:
            # Fallback: log to stderr n·∫øu queue full
            print(f"Log queue full, dropping: {record.getMessage()}", file=sys.stderr)
            
    async def _process_logs(self) -> None:
        """Background task x·ª≠ l√Ω log queue."""
        batch = []
        last_flush = time.time()
        
        while self.is_running or not self.log_queue.empty():
            try:
                # Collect batch ho·∫∑c timeout
                while len(batch) < self.batch_size:
                    try:
                        record = await asyncio.wait_for(
                            self.log_queue.get(), timeout=0.1
                        )
                        batch.append(record)
                    except asyncio.TimeoutError:
                        break
                
                # Flush n·∫øu c√≥ batch ho·∫∑c timeout
                current_time = time.time()
                if batch and (
                    len(batch) >= self.batch_size or 
                    current_time - last_flush >= self.flush_interval
                ):
                    await self._flush_batch(batch)
                    batch.clear()
                    last_flush = current_time
                    
            except Exception as e:
                print(f"Error in log processing: {e}", file=sys.stderr)
                
        # Final flush
        if batch:
            await self._flush_batch(batch)
            
    async def _flush_batch(self, batch: List[logging.LogRecord]) -> None:
        """Flush batch of log records to handlers."""
        if not batch or not self.handlers:
            return
            
        def write_logs():
            for record in batch:
                for handler in self.handlers:
                    try:
                        handler.emit(record)
                    except Exception as e:
                        print(f"Handler error: {e}", file=sys.stderr)
                        
        # Ch·∫°y I/O trong thread pool
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(self.executor, write_logs)
        
    async def _flush_remaining(self) -> None:
        """Flush all remaining logs."""
        remaining = []
        try:
            while True:
                record = self.log_queue.get_nowait()
                remaining.append(record)
        except asyncio.QueueEmpty:
            pass
            
        if remaining:
            await self._flush_batch(remaining)


class TextFormatter(logging.Formatter):
    """Formatter ƒë·ªÉ t·∫°o traditional text logs v·ªõi context support."""
    
    def __init__(self, include_context: bool = True):
        # Format: 2025-06-20 09:15:30,123 [INFO] module.function:42 - Message
        super().__init__(
            fmt="%(asctime)s [%(levelname)s] %(name)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S"
        )
        self.include_context = include_context
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record th√†nh text v·ªõi context support."""
        # Base formatting
        formatted = super().format(record)
        
        if not self.include_context:
            return formatted
              # Th√™m context information n·∫øu c√≥
        context_parts = []
        
        # Th√™m request_id n·∫øu c√≥
        request_id = getattr(record, 'request_id', None)
        if request_id:
            context_parts.append(f"req_id={request_id}")
            
        # Th√™m context n·∫øu c√≥
        context = getattr(record, 'context', None)
        if context and isinstance(context, dict):
            context_str = " ".join([f"{k}={v}" for k, v in context.items()])
            context_parts.append(context_str)
            
        # Th√™m function info n·∫øu c√≥
        if hasattr(record, 'funcName') and record.funcName:
            context_parts.append(f"func={record.funcName}")
            
        if hasattr(record, 'lineno') and record.lineno:
            context_parts.append(f"line={record.lineno}")
        
        # Append context to message
        if context_parts:
            context_info = " | ".join(context_parts)
            formatted = f"{formatted} | {context_info}"
            
        # Th√™m exception info n·∫øu c√≥
        if record.exc_info:
            formatted += "\n" + self.formatException(record.exc_info)
            
        return formatted


class AsyncLogger:
    """
    High-performance async logger v·ªõi traditional text format.
    
    Features:
    - Non-blocking logging via async queue
    - Traditional text output for readability
    - Request/context tracking
    - Rotating file handlers
    - Performance optimized
    """
    
    def __init__(self, name: str, async_handler: AsyncLogHandler):
        self.name = name
        self.async_handler = async_handler
        self._context: Dict[str, Any] = {}
        self._request_id: Optional[str] = None
        
    def set_context(self, **kwargs) -> None:
        """Set logging context for this logger instance."""
        self._context.update(kwargs)
        
    def clear_context(self) -> None:
        """Clear logging context."""
        self._context.clear()
        
    def set_request_id(self, request_id: str) -> None:
        """Set request ID for tracing."""
        self._request_id = request_id
        
    def generate_request_id(self) -> str:
        """Generate v√† set new request ID."""
        request_id = str(uuid.uuid4())[:8]
        self.set_request_id(request_id)
        return request_id
        
    async def _log(self, level: int, message: str, **kwargs) -> None:
        """Internal async logging method."""
        record = logging.LogRecord(
            name=self.name,
            level=level,
            pathname="",
            lineno=0,
            msg=message,
            args=(),
            exc_info=None
        )
        
        # Th√™m context
        if self._context:
            setattr(record, 'context', self._context.copy())
            
        # Th√™m request_id
        if self._request_id:
            setattr(record, 'request_id', self._request_id)
            
        # Th√™m extra kwargs
        for key, value in kwargs.items():
            setattr(record, key, value)
            
        await self.async_handler.log_async(record)
        
    async def debug(self, message: str, **kwargs) -> None:
        """Log debug message."""
        await self._log(logging.DEBUG, message, **kwargs)
        
    async def info(self, message: str, **kwargs) -> None:
        """Log info message."""
        await self._log(logging.INFO, message, **kwargs)
        
    async def warning(self, message: str, **kwargs) -> None:
        """Log warning message."""
        await self._log(logging.WARNING, message, **kwargs)
        
    async def error(self, message: str, **kwargs) -> None:
        """Log error message."""
        await self._log(logging.ERROR, message, **kwargs)
        
    async def critical(self, message: str, **kwargs) -> None:
        """Log critical message."""
        await self._log(logging.CRITICAL, message, **kwargs)


class AsyncLoggerConfig:
    """Async-aware logger configuration manager v·ªõi text format."""
    
    _configured = False
    _async_handler: Optional[AsyncLogHandler] = None
    _loggers: Dict[str, AsyncLogger] = {}
    
    @classmethod
    async def configure_logging(
        cls,
        level: int = logging.INFO,
        log_to_file: bool = True,
        log_file_path: Optional[Path] = None,
        max_file_size: int = 10 * 1024 * 1024,  # 10MB
        backup_count: int = 5,
        include_context: bool = True,
        max_queue_size: int = 10000,
        batch_size: int = 100,
        flush_interval: float = 1.0
    ) -> None:
        """
        Configure async logging system v·ªõi text format.
        
        Args:
            level: Logging level
            log_to_file: Enable file logging
            log_file_path: Path to log file
            max_file_size: Max size per log file
            backup_count: Number of backup files
            include_context: Include context in text format
            max_queue_size: Max async queue size
            batch_size: Batch size for processing
            flush_interval: Flush interval in seconds
        """
        if cls._configured:
            return
            
        # Create async handler
        cls._async_handler = AsyncLogHandler(
            max_queue_size=max_queue_size,
            batch_size=batch_size,
            flush_interval=flush_interval
        )
        
        # Formatter
        formatter = TextFormatter(include_context=include_context)
            
        # Console handler (stderr)
        console_handler = logging.StreamHandler(sys.stderr)
        console_handler.setLevel(level)
        console_handler.setFormatter(formatter)
        cls._async_handler.add_handler(console_handler)
        
        # File handler v·ªõi rotation
        if log_to_file:
            if log_file_path is None:
                log_file_path = Path("logs/polymind.log")
                
            log_file_path.parent.mkdir(parents=True, exist_ok=True)
            
            file_handler = RotatingFileHandler(
                log_file_path,
                maxBytes=max_file_size,
                backupCount=backup_count,
                encoding="utf-8"
            )
            file_handler.setLevel(level)
            file_handler.setFormatter(formatter)
            cls._async_handler.add_handler(file_handler)
            
        # Start async processing
        await cls._async_handler.start()
        
        cls._configured = True
        
    @classmethod
    async def get_logger(cls, name: str) -> AsyncLogger:
        """Get async logger instance."""
        if not cls._configured:
            await cls.configure_logging()
            
        if name not in cls._loggers and cls._async_handler:
            cls._loggers[name] = AsyncLogger(name, cls._async_handler)
            
        return cls._loggers[name]
        
    @classmethod
    async def shutdown(cls) -> None:
        """Shutdown logging system."""
        if cls._async_handler:
            await cls._async_handler.stop()
            cls._configured = False


# Global async logger instance
_global_config = AsyncLoggerConfig()


async def get_logger(name: str) -> AsyncLogger:
    """
    Get async logger instance v·ªõi text format.
    
    Args:
        name: Logger name (typically __name__)
        
    Returns:
        AsyncLogger instance
        
    Example:
        logger = await get_logger(__name__)
        await logger.info("Text log message")
    """
    return await _global_config.get_logger(name)


async def configure_logging(**kwargs) -> None:
    """Configure async logging system v·ªõi text format."""
    await _global_config.configure_logging(**kwargs)


async def shutdown_logging() -> None:
    """Shutdown logging system gracefully."""
    await _global_config.shutdown()


# Context manager for request tracing
class LogContext:
    """Context manager cho request-scoped logging."""
    
    def __init__(self, logger: AsyncLogger, **context):
        self.logger = logger
        self.context = context
        self.old_context = {}
        
    async def __aenter__(self):
        self.old_context = self.logger._context.copy()
        self.logger.set_context(**self.context)
        return self.logger
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        self.logger._context = self.old_context


# Decorator for automatic request ID generation
def with_request_id(func):
    """Decorator t·ª± ƒë·ªông t·∫°o request ID cho async functions."""
    async def wrapper(*args, **kwargs):
        logger = await get_logger(func.__module__)
        request_id = logger.generate_request_id()
        
        async with LogContext(logger, request_id=request_id):
            await logger.info(f"Starting {func.__name__}")
            try:
                result = await func(*args, **kwargs)
                await logger.info(f"Completed {func.__name__}")
                return result
            except Exception as e:
                await logger.error(f"Error in {func.__name__}: {e}")
                raise
                
    return wrapper


# Convenience functions for quick logging
async def log_info(message: str, logger_name: str = "__main__", **kwargs) -> None:
    """Quick info logging."""
    logger = await get_logger(logger_name)
    await logger.info(message, **kwargs)


async def log_error(message: str, logger_name: str = "__main__", **kwargs) -> None:
    """Quick error logging."""
    logger = await get_logger(logger_name)
    await logger.error(message, **kwargs)


async def log_debug(message: str, logger_name: str = "__main__", **kwargs) -> None:
    """Quick debug logging."""
    logger = await get_logger(logger_name)
    await logger.debug(message, **kwargs)

```

## File ..\polymind\src\utils\__init__.py:
```python
# Generated by Copilot
"""Utility modules for the server."""

from .async_logger import get_async_logger, configure_async_logging, shutdown_logging

__all__ = ["get_async_logger", "configure_async_logging", "shutdown_logging"]

```

